{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0396410",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "El Support Vector Machine (SVM) es un algoritmo de aprendizaje supervisado utilizado principalmente para clasificación y regresión. Su objetivo es encontrar el hiperplano que mejor separa las clases en el espacio de características, maximizando el margen entre los puntos de datos más cercanos de cada clase (vectores de soporte). SVM puede trabajar con datos linealmente separables y, mediante el uso de funciones kernel, también puede manejar casos no lineales. Es conocido por su eficacia en espacios de alta dimensión y su robustez frente al sobreajuste.\n",
    "\n",
    "* Algoritmo basado en aprendizaje `supervisado`, clasificacion o etiquetado\n",
    "* Es un algoritmo capaz de realizar `regresión(continuo)` y `clasificación(discreto)` (lineal y no lineal)\n",
    "* Funciona muy bien para `conjuntos de datos complejos de tamaño pequeño` o mediano\n",
    "* Puedes aplicarse de diferentes formas en función del conjunto de datos:\n",
    "    * Conjuntos de datos linealmente separables:\n",
    "        * Hard Margin Classification\n",
    "        * Soft Margin Classification\n",
    "    * Conjuntos de datos linealmente no separables:\n",
    "        * Kernels\n",
    "\n",
    "## Conjunto de datos linealmente separable\n",
    "Es un conjunto de datos que tiene caracteristicas de entrada y de salida, con un conjunto de datos linealmente separable que puede dividir cada caracteristica y generar una funcion hipotesis. Sin embargo en conjuntos de datos que son separables linealmente se pueden tomar varios ejemplos de hipotesis de modelos ajustados que separan los elementos de cada conjunto de datos de negativos y positivos. Claramente cada modelo de hipotesis puede ser malo bueno o actue de otra manera en el modelamiento. Por lo tanto se pueden hacer uso de regresiones o modelos matematicos que dividen perfectamente los modelos hipotesis.\n",
    "\n",
    "EL modelo *SVM* es un algoritmo que no solo separa las dos clases, sino que intenta mantener el limite de decision lo mas alejado posible de los ejemplos de entrenamiento `large margin classification)`\n",
    "\n",
    "<img src=\"Images/svm.png\" alt=\"svm\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c0b24",
   "metadata": {},
   "source": [
    "## Hard Margin Classification\n",
    "La clasificación de margen duro (*Hard Margin Classification*) es una técnica utilizada en SVM cuando los datos son `perfectamente separables de manera lineal`, es decir, no existen errores de clasificación. El objetivo es encontrar el hiperplano que separa las clases con el mayor margen posible, asegurando que todos los puntos de datos queden correctamente clasificados y fuera del margen. Sin embargo, esta técnica no es adecuada para conjuntos de datos con ruido o solapamiento entre clases, ya que no permite errores y puede llevar a modelos poco robustos ante datos reales.\n",
    "\n",
    "Añadir mas ejemplos de entrenamiento fuera de las lineas de puntos no alteran el modelo, esta determinado por los ejemplos mas cercanos del limite de decision, conocidos como `support vectors`.\n",
    "\n",
    "* El método que se acaba de presentar obliga de manera estricta a que todos los ejemplos de entrenamiento de cada una de las clases se encuentren detrás de la línea de puntos\n",
    "* Este método tiene dos problemas fundamentales:\n",
    "    * Sólo funciona con conjuntos de datos linealmente separables\n",
    "    * Es muy sensible a datos anómalos\n",
    "    \n",
    "<img src=\"Images/hmc.png\" alt=\"alt text\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af9a1b",
   "metadata": {},
   "source": [
    "## Construccion del modelo lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f81a2e",
   "metadata": {},
   "source": [
    "### Limite de decision\n",
    "#### Función de coste\n",
    "\n",
    "La función de coste en SVM está relacionada con la regresión logística:\n",
    "\n",
    "$$\n",
    "J(h_{\\theta},y) = -y\\log(h_{\\theta}(x)) - (1-y)\\log(1-h_{\\theta}(x))\n",
    "$$\n",
    "\n",
    "Actúa dependiendo del valor de $y$ (0 o 1).\n",
    "\n",
    "<img src=\"Images/reglogistica.png\" alt=\"Regresión logística\" width=\"500\"/>\n",
    "\n",
    "Ahora, parametrizada por $J(\\theta, y)$:\n",
    "\n",
    "$$\n",
    "J(\\theta, y) = -y\\log\\left(\\frac{1}{1+e^{-(\\theta_0 + \\theta_1 x)}}\\right) - (1-y)\\log\\left(1-\\frac{1}{1+e^{-(\\theta_0 + \\theta_1 x)}}\\right)\n",
    "$$\n",
    "\n",
    "Donde: $\\theta = \\theta_0 + \\theta_1 x$\n",
    "\n",
    "La ecuación tiene dos lados, según la respuesta sea 0 o 1.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"Images/fcoste.png\" alt=\"Función de coste\" width=\"700\"/>\n",
    "</p>\n",
    "\n",
    "$$\n",
    "J(\\theta, y)=0 \\rightarrow \\theta_0 + \\theta_1 x \\geq 1 \\hspace{1cm} J(\\theta, y)=0 \\rightarrow \\theta_0 + \\theta_1 x \\leq -1\n",
    "$$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"Images/fcosteJ.png\" alt=\"Coste SVM\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    "La función de coste para SVM se expresa como:\n",
    "$$\n",
    "J(\\theta, y) =\n",
    "\\begin{cases}\n",
    "    \\max(0, 1 - (\\theta_0 + \\theta_i x_i)) & \\text{si } y = 1 \\\\\n",
    "    \\max(0, 1 + (\\theta_0 + \\theta_i x_i)) & \\text{si } y = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "Al igual que la regresion logistica se pueden unir para tener una misma equacion:\n",
    "$$\n",
    "J(\\theta,y) = ymax(0,1-\\theta)+(1-y)max(0,1+\\theta)\n",
    "$$\n",
    "\n",
    "Esta funcion se ve referenciada como `Hinge loss`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e1060",
   "metadata": {},
   "source": [
    "#### Funcion Hipotesis\n",
    "\n",
    "**Regresion Logistica**: $h_{\\theta}(x) = g(\\theta_0 + \\theta_1 x)$, seguia siendo un valor continuo y por lo tanto se hacia el uso de un threshold o un limite que clasificara en otros limites.\n",
    "\n",
    "**SVM**: \n",
    "$\n",
    "h_{\\theta}(x) = \n",
    "\\begin{cases}\n",
    "    1 & \\text{si } \\theta_0 + \\theta_1 \\leq 0\\\\\n",
    "    0 & \\text{en caso contrario}\n",
    "\\end{cases}\n",
    "$\n",
    "La funcion hipotesis es esta que predice un valor discreto que se esta buscando en los limites sin necesidad de un threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47c457",
   "metadata": {},
   "source": [
    "#### Soft Margin Classification\n",
    "* Para evitar los problemas citados anteriormente, debe utilizarse un modelo más flexible: Soft Margin Classification.\n",
    "* El objetivo de este modelo es mantener un balance adecuado entre mantener el límite de decisión lo más alejado posible de los ejemplos de entrenamiento y disminuir la sensibilidad a los ejemplo anómalos.\n",
    "* En las implementaciones de SVM normalmente esto se controla mediante un hiperparámetro que suele estar representado mediante la letra C para modificar la flexibilidad del modelo.\n",
    "* Utilizando este metodo el algoritmo genera limites de decision menos estrictos que generalizan mejor para nuevos ejemplos.\n",
    "\n",
    "Tambien se podria llegar a usar esta clasisifcion con hiperparametros con modelos no separeblas en su totalidad, tomandolas como anomalias y sustrayendo de igual forma la parte que importa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f54f29",
   "metadata": {},
   "source": [
    "### Regresion Polinomica | Kernel\n",
    "\n",
    "**Clasificacion no lineal**\n",
    "* Las clasificaciones SVM lineales son eficientes y funcionan muy bien, sin embargo, existen *conjuntos de datos que no son linealmente separables*\n",
    "<p align=\"center\">\n",
    "    <img src=\"Images/nolineal.png\" alt=\"alt text\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    "La regresión polinómica es una técnica que permite modelar relaciones no lineales entre las variables independientes y la variable dependiente, extendiendo la regresión lineal al incluir términos polinómicos de mayor grado. En el contexto de SVM, se utiliza el *kernel polinómico* para transformar los datos originales en un espacio de mayor dimensión donde puedan ser linealmente separables. Esto permite al algoritmo encontrar límites de decisión más complejos y adaptarse a patrones no lineales presentes en los datos.\n",
    "\n",
    "El kernel polinómico tiene la siguiente forma:\n",
    "\n",
    "$$\n",
    "K(x, x') = (\\gamma \\langle x, x' \\rangle + r)^d\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\gamma$ es un coeficiente de escala,\n",
    "- $r$ es un término independiente,\n",
    "- $d$ es el grado del polinomio.\n",
    "\n",
    "Esta técnica es útil cuando los datos presentan relaciones complejas que no pueden ser capturadas por un modelo lineal, permitiendo una mayor flexibilidad en la clasificación.\n",
    "\n",
    "Se crean un conjunto de caracteristicas polinomicas que permiten la creacion de limites de decision no lineales.\n",
    "\n",
    "Para lo que llevamos la funcion hipotesis esta establecida por $h_{\\theta}(x) = \\theta_0 + \\theta_1 x$ es una recta o lineal y con lo siguiente queremos es una funcion no lineal y para ello solo se debe agregar un apartado polinomico $h_{\\theta}(x) = \\theta_0 + \\theta_1 x + \\theta_2 z^2...$\n",
    "\n",
    "<img src=\"Images/polinomico.png\" alt=\"alt text\" width=\"500\"/>\n",
    "\n",
    "#### Creacion de caracteristicas polinomicas\n",
    "* Utilizar características polinómicas para generar límites de decisión no lineales tiene un gran inconveniente:\n",
    "    * Si se dispone de polinomios con un grado bajo, no pueden generarse limites de decisión complejos\n",
    "    * Si se dispone de polinomios con un grado alto, se generan un gran número de características, lo que requiere una capacidad de computo elevada y el modelo es lento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216bba2",
   "metadata": {},
   "source": [
    "#### Gaussian Kernel\n",
    "El *Gaussian Kernel* (también conocido como *Radial Basis Function Kernel* o RBF Kernel) es una función utilizada en SVM para transformar datos no linealmente separables en un espacio de mayor dimensión donde puedan ser separados por un hiperplano. Este kernel mide la similitud entre dos puntos y permite que el modelo encuentre límites de decisión complejos y no lineales.\n",
    "\n",
    "La forma matemática del kernel gaussiano es:\n",
    "\n",
    "$$\n",
    "K(x, x') = \\exp\\left(-\\frac{\\|x - x'\\|^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $x$ y $x'$ son dos vectores de características,\n",
    "- $\\|x - x'\\|^2$ es la distancia euclidiana al cuadrado entre los vectores,\n",
    "- $\\sigma$ es el parámetro que controla el ancho del kernel (también conocido como *bandwidth*).\n",
    "\n",
    "**Características principales:**\n",
    "- Permite modelar relaciones altamente no lineales.\n",
    "- El parámetro $\\sigma$ determina la influencia de cada punto de datos: valores pequeños de $\\sigma$ hacen que el kernel sea más sensible a los puntos cercanos, mientras que valores grandes lo hacen más general.\n",
    "- Es ampliamente utilizado por su capacidad para manejar datos complejos y por su flexibilidad.\n",
    "\n",
    "**Ventajas:**\n",
    "- No requiere la creación explícita de características polinómicas de alto grado.\n",
    "- Es robusto frente a la presencia de ruido y datos anómalos.\n",
    "- Generaliza bien en problemas de clasificación con fronteras no lineales.\n",
    "\n",
    "**Aplicación en SVM:**\n",
    "El kernel gaussiano permite que el SVM encuentre límites de decisión curvos y complejos, adaptándose a la estructura real de los datos. Es especialmente útil cuando los datos no pueden ser separados por una línea recta o un plano en el espacio original.\n",
    "\n",
    "* Soluciona el problema que presenta la creacion de caracteristicas polinomicas.\n",
    "* Dada una caracteristica x, calcula nuevas caracteristicas en funcion de la proximidad a unos puntos de referencia que se establecen.\n",
    "\n",
    "¿vi y con esos puntos de referencia como los escojo?\n",
    "\n",
    "Existen diferentes estrategias para seleccionar los puntos de referencia, una de las formas mas comunes es seleccionar un punto de referencia por cada uno de los ejemplos de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
