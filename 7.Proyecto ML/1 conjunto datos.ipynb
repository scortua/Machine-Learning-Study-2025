{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70c0298",
   "metadata": {},
   "source": [
    "# CONJUNTO DE DATOS\n",
    "\n",
    "Los conjuntos de datos son colecciones estructuradas de información que se utilizan para analizar, entrenar modelos y extraer conocimiento. Pueden contener datos numéricos, categóricos, imágenes, texto, entre otros tipos. La calidad y el tamaño del conjunto de datos son fundamentales para obtener resultados precisos y confiables en cualquier proyecto de análisis de datos o aprendizaje automático.\n",
    "\n",
    "* Un conjunto de datos es una parte esencial en la resolucion de un problema mediante el uso de machine learning.\n",
    "\n",
    "El conjunto de datos es tan importante como el algoritmo para tratar los datos, pero realmente el problema es del conjunto de datos mas no de los algoritmos por su complejidad.\n",
    "\n",
    "* Las caracteristicas son un atributo o grupo de atributos que constituyen una propiedad particular o un conjunto de propiedades que es unico, mediable y diferenciable.\n",
    "\n",
    "Conjunto de ejemplos representativos al problema que se quiere resolver, obteniendo caracteristicas de los datos y de esas caracteristicas de entrada obtener la hipotesis y la manera de obtener el conjunto de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110f072",
   "metadata": {},
   "source": [
    "## Recopilando\n",
    "\n",
    "* Disponer de una cantidad suficiente de datos\n",
    "* Esencial utilizar un conjunto de datos que es representativo del problema practico que se desea resolver\n",
    "* Los datos deben ser de calidad\n",
    "* Debe seleccionarse un conjunto de caracteristicas adecuado, minimizando el numero de caracteristicas irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82e4f4",
   "metadata": {},
   "source": [
    "# OVERFITTING\n",
    "\n",
    "El sobreentrenamiento, conocido como *overfitting*, ocurre cuando un modelo de aprendizaje automático se ajusta demasiado a los datos de entrenamiento, capturando el ruido y las particularidades específicas de ese conjunto en lugar de aprender patrones generales. Esto provoca que el modelo tenga un desempeño excelente en los datos de entrenamiento pero un rendimiento pobre en datos nuevos o no vistos, ya que no logra generalizar correctamente.\n",
    "\n",
    "El overfitting suele presentarse cuando el modelo es demasiado complejo en relación con la cantidad y calidad de los datos disponibles, o cuando se entrena durante demasiadas iteraciones. Para evitarlo, se pueden emplear técnicas como la regularización, la reducción de la complejidad del modelo, el uso de más datos, o la validación cruzada.\n",
    "\n",
    "![overfitting](Images/overfitting.png)\n",
    "\n",
    "* Si el conjunto de datos tiene muchas caracteristicas, es posible que la funcion hipotesis generada por el algoritmo se adapte muy bien al conjunto de entrenamiento $J_(\\theta)=0$ pero falle al generalizar con nuevos ejemplos.\n",
    "\n",
    "- regresion lineal - regresion polinomica - caracteristicas polinomicas (flexible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86255e9a",
   "metadata": {},
   "source": [
    "# UNDERFITTING\n",
    "\n",
    "El *underfitting* ocurre cuando un modelo de aprendizaje automático es demasiado simple para capturar los patrones subyacentes en los datos. Esto provoca que el modelo tenga un rendimiento deficiente tanto en los datos de entrenamiento como en los datos nuevos, ya que no logra aprender la relación entre las variables de entrada y salida.\n",
    "\n",
    "El underfitting suele presentarse cuando el modelo tiene muy pocos parámetros, cuando se seleccionan características irrelevantes o insuficientes, o cuando el tiempo de entrenamiento es demasiado corto. Para evitarlo, se recomienda aumentar la complejidad del modelo, seleccionar mejores características y asegurarse de que el modelo tenga suficiente capacidad para aprender de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d8fe4",
   "metadata": {},
   "source": [
    "![underfitting](Images/underfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a5595",
   "metadata": {},
   "source": [
    "# Solucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbdf8fd",
   "metadata": {},
   "source": [
    "# OVERFITTING\n",
    "\n",
    "* Aumentar el conjunto de datos\n",
    "* Reduccion del numero de caracteristicas -> entre mas datos mas flexible y por ende ocurre sobre entrenamiento y necesitamos que sea exacto en su mayoria para mejorar en el algoritmo.\n",
    "    * Seleccion manual de las caracteristicas que se pueden mantener: ente muchas caracteristicas es mejor seleccionar las caracteristicas que nosotros entendemos como mejor opcion para entrenar correctamente el modelo.\n",
    "    * Utilizar un algoritmo para la seleccion de caracteristicas: algo similar como ranom forest o cualquier tipo o estilo de algoritmo que permita encontrar las caracteristicas mas correctas y que alimenten al algoritmo de manera automatica.\n",
    "    * Utilizar un algoritmo para la extraccion de caracteristicas: Reduccion del sistema transformando todo el sistema para mantener la originalidad de los datos pero manteniendo la distribucion de esos datos importantes.\n",
    "* Regularizacion: Añair penalizacion en el modelo para corregir al modelo, tratar de reducir valores, disminuir valores y por ende mejorar el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7e464",
   "metadata": {},
   "source": [
    "### Regularizacion\n",
    "\n",
    "* La regularización agrega una penalización en los diferentes parámetros del modelo para reducir la libertad del modelo. Por lo tanto, es menos probable que el modelo se ajuste al ruido de los datos de entrenamiento y mejorará las capacidades de generalización del mismo.\n",
    "* Mantiene todas las características, pero reduce la magnitud de los parámetros 0, a lo mejor si se tienen 10 atributos de entradas pero por si mismos los datos no son del todo utiles pues que no se centre tanto en esto para mejorar el entrenamiento.\n",
    "* La regularización funciona bien cuando tenemos muchas características ligeramente útiles\n",
    "\n",
    "Lo que pasa con la flexibilidad es que se establece muy bien con datos similares a los datos de alimentacion, pero generalmente no es asi. Lo que pasa con la regularizacion es penalizar para regular. Basicamente en lugar de tener una unica funcion de coste general se le agrega un parametro que permita entender un poco el error a los datos que se construyen, pero sin dañar la tendencia de los datos.\n",
    "\n",
    "$$\n",
    "J_{\\theta}(x)\\\\\n",
    "J_{\\theta} + \\lambda \\sum_{j=1}^{n}\\theta_{j}^2\n",
    "$$\n",
    "Si $\\lambda = 0$\n",
    "$$\n",
    "J_{\\theta} + 0 \\sum_{j=1}^{n}\\theta_{j}^2\n",
    "$$\n",
    "Entonces no se le agregaria penalizacion y si poco a poco se va aumentando $\\lambda$ pues:\n",
    "$$\n",
    "J_{\\theta} + \\infty \\sum_{j=1}^{n}\\theta_{j}^2\n",
    "$$\n",
    "Entonces siempre tendremos un error que tienda a infinito, porque el error siempre sera grande entonces el *Gradient Descent* seguira trabajando y por eso se colocan valores al sistema que añadan la penalizacion en un tope perfecto para que el algoritmo sea exacto lo que se requiere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ec69a",
   "metadata": {},
   "source": [
    "# Evaluacion de hipotesis\n",
    "\n",
    "Nosotros de forma visual podemos saber como se actua en un sistema con sus parametro de entra, pero cuando estos parametros sean demasiados ya no se pueden graficar y por tanto ya no sabemos a cierta ciencia como actuan, entonces como solucionamos esto.\n",
    "\n",
    "Para poder evaluarlo se requiere una forma de evaluar la funcion hipotesis evaluada y dividir nuestro conjunto de datos en subconjuntos para poder estudiar la funcion hipotesis.\n",
    "\n",
    "## Evaluacion HIpotesis\n",
    "\n",
    "Digamos que tenemos como en el ejemplo, un conjunto de datos, con entradas y una salida. Al aplicar un conjunto de entrenamiento se genera una funcion hipotesis sobre entrenada que da exactamente la misma prediccion y por ello cuando llega un ejemplo nuevo y se hace una prediccion lo hace erroneamente por culpa de ese overfitting.\n",
    "\n",
    "Para tratar de encontrar estos problemas, se divide en 2 conjuntos como train set y test set.\n",
    "* train set 60% - 70%\n",
    "* test set 40% - 30%\n",
    "\n",
    "De manera que ahora cambia el estudio, pues train set entrenamos un modelo pero que repetira el error, con el test set se elimina una caracteristica y se vuelve a mostrar como el algoritmo dispone de estos datos y al comparar los datos que se muestran y se puede evidenciar el error de predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92773c1c",
   "metadata": {},
   "source": [
    "## Seleccion de modelo\n",
    "Estamos tratando de resolver un problema determinado mediante aprendizaje automatico.\n",
    "1. Recopilar ese conjunto de datos de experiencias pasadas\n",
    "2. Etiquetar con cada uno de los ejemplos con una clase positiva y otra negativa\n",
    "3. Partir el conjunto en *train-set* y en *test-set*\n",
    "\n",
    "Que modelo utilizo?\n",
    "Probablemente tendre que estudiar que modelo iria acorde con el conjunto de datos con el tanteo de los diferentes algoritmos.\n",
    "\n",
    "Al hacer el estudio de modelo con el train test tendriamos:\n",
    "- Error test-set grande y Error train-set pequeño -> OVERFITTING\n",
    "- Error test-set grande y Error train-set grande -> MODELO INADECUADO\n",
    "\n",
    "Por tanto se empieza a tantear aumentando las caracteristicas de entrada y llegar hasta el momento en que los datos caracteristicos se estabilizan al modelo del algoritmo.\n",
    "\n",
    "Si hay tantos modelos de uso puede que se produsca overfitting por el uso de ciertos datos entonces si hay un ejemplo nuevo que no esta en ninguno de los 2 conjuntos caiga en errores. Para solucionar esto se debe dividir el conjunto inicial en 2 para un subconjunto de validacion.\n",
    "\n",
    "Train-set para entrenar modelos, el Validation-set para validar si se esta generando overfitting en el train-set y se usa el test-set como ultima instancia para verificar si el algoritmo construizo funciona correctamente despues de verificar su veracidad en el train y validation set.\n",
    "\n",
    "* Dividimos el conjunto de datos en entrenamiento, validación y pruebas\n",
    "* Se calcula la función hipótesis con el subconjunto de entrenamiento (se calculan los parámetros e minimizando el error de entrenamiento $J(\\theta)$)\n",
    "* Se calcula el número de características óptimo mediante la evaluación de las hipótesis anteriores con el subconjunto de validación\n",
    "* Se evalúa la función hipótesis resultante mediante el subconjunto de pruebas calculando su error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819cb97",
   "metadata": {},
   "source": [
    "### Regresion Lineal\n",
    "$$\n",
    "h_{\\theta}^{(1)}(x) = \\theta_0 + \\theta_1 x_1\n",
    "$$\n",
    "La regresión lineal es un modelo sencillo que busca ajustar una línea recta a los datos, relacionando una variable independiente $x_1$ con la variable dependiente a través de los parámetros $\\theta_0$ y $\\theta_1$. Es útil cuando la relación entre las variables es aproximadamente lineal y permite interpretar fácilmente el efecto de cada característica sobre la variable objetivo.\n",
    "\n",
    "**Ventajas:** Fácil de interpretar, rápido de entrenar, útil para relaciones simples.  \n",
    "**Desventajas:** No captura relaciones no lineales, puede subajustar datos complejos.\n",
    "\n",
    "### Regresión Polinómica\n",
    "\n",
    "$$\n",
    "h_{\\theta}^{(2)}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_{\\theta}^{(3)}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_{\\theta}^{(4)}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3 + \\theta_4 x_1^4\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_{\\theta}^{(5)}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3 + \\theta_4 x_1^4 + \\theta_5 x_1^5\n",
    "$$\n",
    "\n",
    "La regresión polinómica extiende la regresión lineal al incluir términos de mayor grado ($x_1^2$, $x_1^3$, etc.), permitiendo ajustar curvas más complejas a los datos. Cada grado adicional aumenta la flexibilidad del modelo para capturar patrones no lineales.\n",
    "\n",
    "**Ventajas:** Puede modelar relaciones complejas y no lineales entre variables.  \n",
    "**Desventajas:** Riesgo de sobreajuste si el grado es muy alto, interpretación más difícil, mayor complejidad computacional.  \n",
    "**Uso recomendado:** Cuando los datos muestran una tendencia curva y la regresión lineal no es suficiente para capturar la relación."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
