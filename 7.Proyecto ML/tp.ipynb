{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8a5b45",
   "metadata": {},
   "source": [
    "# PIPELINES Y TRANSFORMADORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cccbd",
   "metadata": {},
   "source": [
    "## TRANSFORMADORES\n",
    "Los transformadores en machine learning son herramientas fundamentales para la preparación y procesamiento de datos antes de entrenar modelos. Un transformador es un objeto que implementa métodos para ajustar (fit) y transformar (transform) datos, permitiendo aplicar operaciones como escalado, normalización, codificación de variables categóricas, imputación de valores faltantes, entre otros.\n",
    "\n",
    "### Características principales de los transformadores\n",
    "\n",
    "- **Ajuste (`fit`)**: Analiza los datos de entrada para aprender parámetros necesarios para la transformación (por ejemplo, calcular la media y desviación estándar para normalizar).\n",
    "- **Transformación (`transform`)**: Aplica la transformación aprendida a los datos, modificando su representación.\n",
    "- **Composición**: Los transformadores pueden combinarse en secuencias (pipelines) para aplicar múltiples transformaciones de manera ordenada y reproducible.\n",
    "\n",
    "### Ejemplos comunes de transformadores\n",
    "\n",
    "- **StandardScaler**: Normaliza los datos para que tengan media cero y desviación estándar uno.\n",
    "- **MinMaxScaler**: Escala los datos a un rango específico, generalmente entre 0 y 1.\n",
    "- **OneHotEncoder**: Convierte variables categóricas en variables binarias.\n",
    "- **SimpleImputer**: Rellena valores faltantes con la media, mediana o un valor constante.\n",
    "\n",
    "### Importancia en el flujo de trabajo\n",
    "\n",
    "El uso de transformadores garantiza que el preprocesamiento de los datos sea consistente y reproducible, especialmente cuando se integran en pipelines. Esto facilita la validación cruzada, la automatización y la implementación de modelos en producción.\n",
    "\n",
    "En resumen, los transformadores son esenciales para preparar los datos de manera adecuada, mejorar el rendimiento de los modelos y asegurar la integridad del proceso de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d1af7",
   "metadata": {},
   "source": [
    "## PIPELINES\n",
    "Los **pipelines** en machine learning son estructuras que permiten encadenar múltiples pasos de procesamiento y modelado de datos en un flujo ordenado y reproducible. Un pipeline integra transformadores y modelos en una sola entidad, facilitando la automatización y la gestión del ciclo completo de aprendizaje automático.\n",
    "\n",
    "### Características principales de los pipelines\n",
    "\n",
    "- **Secuencia de pasos**: Un pipeline está compuesto por una serie de pasos, donde cada paso puede ser un transformador (preprocesamiento) o un estimador (modelo de machine learning).\n",
    "- **Reproducibilidad**: Al definir el flujo completo en un solo objeto, se garantiza que el procesamiento de datos y el entrenamiento del modelo sean consistentes en cada ejecución.\n",
    "- **Automatización**: Permite aplicar el mismo flujo de trabajo a nuevos datos sin necesidad de repetir manualmente cada transformación.\n",
    "- **Validación cruzada integrada**: Facilita la validación cruzada de todo el proceso, evitando el riesgo de fugas de datos entre el preprocesamiento y el entrenamiento.\n",
    "\n",
    "### Ejemplo de pipeline típico\n",
    "\n",
    "Un pipeline puede incluir los siguientes pasos:\n",
    "1. **Imputación de valores faltantes** (por ejemplo, con `SimpleImputer`)\n",
    "2. **Escalado de características** (por ejemplo, con `StandardScaler`)\n",
    "3. **Codificación de variables categóricas** (por ejemplo, con `OneHotEncoder`)\n",
    "4. **Entrenamiento de un modelo** (por ejemplo, con `RandomForestClassifier`)\n",
    "\n",
    "### Ventajas de usar pipelines\n",
    "\n",
    "- **Simplicidad**: Reduce la complejidad del código y mejora la legibilidad.\n",
    "- **Prevención de fugas de datos**: Asegura que las transformaciones se ajusten solo en los datos de entrenamiento.\n",
    "- **Facilidad de despliegue**: El pipeline puede guardarse y reutilizarse en producción.\n",
    "- **Optimización conjunta**: Permite ajustar hiperparámetros de todo el flujo mediante herramientas como `GridSearchCV`.\n",
    "\n",
    "### Implementación en scikit-learn\n",
    "\n",
    "En `scikit-learn`, los pipelines se implementan mediante la clase `Pipeline`. Ejemplo:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "```\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Los pipelines son herramientas esenciales para estructurar, automatizar y asegurar la calidad de los procesos de machine learning, desde el preprocesamiento hasta la predicción final. Facilitan la colaboración, el mantenimiento y el despliegue de soluciones robustas y reproducibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1b538",
   "metadata": {},
   "source": [
    "# Evaluacion de Resultados\n",
    "La evaluación de resultados en machine learning es el proceso de medir el desempeño de un modelo sobre datos de prueba o validación. Es fundamental para determinar si el modelo cumple con los objetivos planteados y para comparar diferentes enfoques.\n",
    "\n",
    "## Objetivos de la evaluación\n",
    "\n",
    "- **Medir la precisión y utilidad del modelo**\n",
    "- **Detectar sobreajuste o subajuste**\n",
    "- **Comparar modelos y seleccionar el mejor**\n",
    "- **Ajustar hiperparámetros y mejorar el rendimiento**\n",
    "\n",
    "## Tipos de métricas de evaluación\n",
    "\n",
    "Las métricas varían según el tipo de problema:\n",
    "\n",
    "### 1. **Clasificación**\n",
    "- **Accuracy (Exactitud):** Proporción de predicciones correctas.\n",
    "- **Precision (Precisión):** Proporción de verdaderos positivos entre los predichos como positivos.\n",
    "- **Recall (Sensibilidad):** Proporción de verdaderos positivos entre los casos realmente positivos.\n",
    "- **F1-score:** Media armónica entre precisión y recall.\n",
    "- **Matriz de confusión:** Tabla que muestra los aciertos y errores por clase.\n",
    "- **ROC-AUC:** Área bajo la curva ROC, mide la capacidad de discriminación.\n",
    "\n",
    "### 2. **Regresión**\n",
    "- **Mean Absolute Error (MAE):** Promedio de errores absolutos.\n",
    "- **Mean Squared Error (MSE):** Promedio de errores al cuadrado.\n",
    "- **Root Mean Squared Error (RMSE):** Raíz cuadrada del MSE.\n",
    "- **R² (Coeficiente de determinación):** Proporción de la varianza explicada por el modelo.\n",
    "\n",
    "### 3. **Clustering**\n",
    "- **Silhouette Score:** Mide la separación entre los grupos.\n",
    "- **Davies-Bouldin Index:** Evalúa la compacidad y separación de los clusters.\n",
    "\n",
    "## Validación cruzada\n",
    "\n",
    "La **validación cruzada** es una técnica para evaluar el modelo de manera más robusta, dividiendo los datos en varios subconjuntos y entrenando/evaluando el modelo en diferentes particiones. La más común es la **k-fold cross-validation**.\n",
    "\n",
    "## Consideraciones importantes\n",
    "\n",
    "- **Evitar fugas de datos:** Las métricas deben calcularse sobre datos no vistos por el modelo durante el entrenamiento.\n",
    "- **Balance de clases:** En problemas desbalanceados, métricas como accuracy pueden ser engañosas; es mejor usar precisión, recall y F1-score.\n",
    "- **Interpretabilidad:** Elegir métricas que sean comprensibles y relevantes para el problema de negocio.\n",
    "\n",
    "## Visualización de resultados\n",
    "\n",
    "- **Curvas ROC y Precision-Recall**\n",
    "- **Gráficos de residuales en regresión**\n",
    "- **Matriz de confusión**\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "La evaluación de resultados es esencial para validar la calidad y utilidad de los modelos de machine learning. Permite tomar decisiones informadas sobre ajustes, selección y despliegue de modelos en producción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670d010",
   "metadata": {},
   "source": [
    "## Matriz de confusion\n",
    "La **matriz de confusión** es una herramienta fundamental para evaluar el desempeño de modelos de clasificación. Permite visualizar el número de predicciones correctas e incorrectas realizadas por el modelo, comparando las clases reales con las clases predichas.\n",
    "\n",
    "### ¿Cómo se interpreta?\n",
    "\n",
    "Una matriz de confusión para un problema de clasificación binaria tiene la siguiente estructura:\n",
    "\n",
    "|                | Predicción Positiva | Predicción Negativa |\n",
    "|----------------|--------------------|--------------------|\n",
    "| **Real Positiva** | Verdadero Positivo (TP) | Falso Negativo (FN) |\n",
    "| **Real Negativa** | Falso Positivo (FP)     | Verdadero Negativo (TN) |\n",
    "\n",
    "- **TP (True Positive):** Casos positivos correctamente clasificados.\n",
    "- **TN (True Negative):** Casos negativos correctamente clasificados.\n",
    "- **FP (False Positive):** Casos negativos clasificados incorrectamente como positivos.\n",
    "- **FN (False Negative):** Casos positivos clasificados incorrectamente como negativos.\n",
    "\n",
    "### Ejemplo visual\n",
    "\n",
    "Supongamos que tenemos los siguientes resultados:\n",
    "\n",
    "|                | Predicción: Sí | Predicción: No |\n",
    "|----------------|:-------------:|:--------------:|\n",
    "| **Real: Sí**   |      50       |      10        |\n",
    "| **Real: No**   |      5        |      35        |\n",
    "\n",
    "- **TP = 50**\n",
    "- **FN = 10**\n",
    "- **FP = 5**\n",
    "- **TN = 35**\n",
    "\n",
    "### ¿Por qué es útil?\n",
    "\n",
    "La matriz de confusión permite calcular métricas como **accuracy**, **precision**, **recall** y **F1-score**, proporcionando una visión más detallada de los errores del modelo y ayudando a identificar posibles problemas como el desbalance de clases.\n",
    "\n",
    "### Visualización en Python\n",
    "\n",
    "Se puede generar fácilmente con `scikit-learn`:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# y_true: etiquetas reales, y_pred: etiquetas predichas\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "```\n",
    "\n",
    "La matriz de confusión es esencial para entender cómo y dónde el modelo está fallando, permitiendo mejorar su desempeño y tomar decisiones informadas.\n",
    "\n",
    "**Precision**\n",
    "- Se calcula dividiendo el numero de verdaderos positivos por la suma del numero de verdaderos positivos y numero de falsos positivos.\n",
    "$$\n",
    "Presicion=\\frac{VerdaderosPositivos}{VerdaderosPositivos+FalsosPostivos}\n",
    "$$\n",
    "**Exhaustividad**\n",
    "- Se calcula dividiendo el numero de verdaderos positivos por la suma del numero de verdaderos positivos y numero de falsos negativos.\n",
    "$$\n",
    "Recall=\\frac{VerdaderosPositivos}{VerdaderosPositivos+FalsosNegativos}\n",
    "$$\n",
    "**F1-score**\n",
    "- Se puede interpretar como un promedio ponderado de la precision y la exactitud recall, donde el F1-score alcanza su mejor valor en 1 y el peor puntaje en 0.\n",
    "- La contribucion relativa de la precision y la exactitud al F1-score es la misma.\n",
    "- La formula es:\n",
    "$$\n",
    "F1=2*\\frac{precision*recall}{precision+recall}\n",
    "$$\n",
    "\n",
    "**Curvas ROC (Receiver Operating Characteristic)**\n",
    "- Las curvas ROC suelen representar la tasa de verdaderos positivos en el eje Y y la una tasa de falsos positivos en el eje X. Esto significa que la esquina superior izquierda de la gráfica es el punto \"ideal\", una tasa de falsos positivos de cero y una tasa de verdaderos positivos de uno. Como consecuencia un área más grande debajo de la curva (AUC) suele ser mejor.\n",
    "\n",
    "Las **curvas ROC** son una herramienta gráfica utilizada para evaluar el rendimiento de modelos de clasificación binaria. Permiten visualizar la relación entre la **tasa de verdaderos positivos** (sensibilidad o recall) y la **tasa de falsos positivos** a diferentes umbrales de decisión.\n",
    "\n",
    "- **Interpretación:** Una curva ROC que se acerca a la esquina superior izquierda indica un modelo con buen poder de discriminación. El área bajo la curva (**AUC**) cuantifica este desempeño: un AUC de 1 representa un modelo perfecto, mientras que un AUC de 0.5 indica un modelo sin capacidad de discriminación.\n",
    "\n",
    "- **Utilidad:** Las curvas ROC son especialmente útiles cuando las clases están desbalanceadas, ya que muestran cómo varía el rendimiento del modelo según el umbral de clasificación.\n",
    "\n",
    "- **Visualización en Python:** Se pueden generar fácilmente con `scikit-learn` usando las funciones `roc_curve` y `RocCurveDisplay`:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "\n",
    "# y_true: etiquetas reales, y_score: probabilidades predichas\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "```\n",
    "Las curvas ROC ayudan a seleccionar el umbral óptimo y comparar diferentes modelos de clasificación.\n",
    "\n",
    "**Curvas PR (Precision-Recall)**\n",
    "- Curva PR: Un área grande debajo de la curva representa tanto alta exactitud como alta precisión, donde la alta precisión se relaciona con una baja tasa de falsos positivos, y la alta exactitud se relaciona con una baja tasa de falsos negativos. La esquina superior izquierda de la gráfica es el punto \"ideal\".\n",
    "\n",
    "Las **curvas Precision-Recall (PR)** son herramientas gráficas que muestran la relación entre la **precisión** y la **exhaustividad (recall)** de un modelo de clasificación a diferentes umbrales de decisión. Son especialmente útiles en problemas con clases desbalanceadas, donde la métrica de precisión puede ser más informativa que la exactitud global.\n",
    "\n",
    "- **Interpretación:** Una curva PR que se acerca a la esquina superior derecha indica un modelo con alto rendimiento, es decir, alta precisión y alta exhaustividad. El área bajo la curva (**AUC-PR**) resume el desempeño general del modelo: valores cercanos a 1 indican mejor rendimiento.\n",
    "\n",
    "- **Utilidad:** Las curvas PR permiten identificar el umbral óptimo para maximizar la precisión y la exhaustividad, y comparar modelos en contextos donde los falsos positivos y falsos negativos tienen diferentes costos.\n",
    "\n",
    "- **Visualización en Python:** Se pueden generar fácilmente con `scikit-learn` usando las funciones `precision_recall_curve` y `PrecisionRecallDisplay`:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "# y_true: etiquetas reales, y_score: probabilidades predichas\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n",
    "```\n",
    "\n",
    "Las curvas PR son fundamentales para evaluar modelos en escenarios donde la clase positiva es poco frecuente y la precisión es crítica.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
