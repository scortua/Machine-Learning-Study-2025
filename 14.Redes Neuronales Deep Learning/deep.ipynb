{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a852b45",
   "metadata": {},
   "source": [
    "# Deep Learning and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4bd56",
   "metadata": {},
   "source": [
    "## Introducción a las Redes Neuronales\n",
    "\n",
    "Las redes neuronales son un modelo computacional inspirado en el funcionamiento del cerebro humano. Están compuestas por nodos llamados \"neuronas\", organizados en capas, que procesan información y aprenden patrones a partir de datos. Estas redes son fundamentales en el campo del aprendizaje profundo (deep learning) y se utilizan para resolver problemas complejos como reconocimiento de imágenes, procesamiento de lenguaje natural y predicción de series temporales.\n",
    "\n",
    "El aprendizaje en redes neuronales se realiza ajustando los pesos de las conexiones entre neuronas mediante algoritmos de optimización, permitiendo que el modelo mejore su desempeño conforme recibe más datos. Gracias a su capacidad para modelar relaciones no lineales y extraer características relevantes, las redes neuronales han revolucionado múltiples áreas de la inteligencia artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea15daa",
   "metadata": {},
   "source": [
    "**Las redes neuronales artificiales o RNA** son o corresponden al componente principal del __deep learning__. Estas redes neuronales artificiales realmente se implementaron en 1943 por un neuropsicologo, pero este se cambio por el support vector por problemas de potencia y simplificacion, pero en los 90s se volve a retomar. Para el 2000 se implemento una **Red Neuronal Convolucional**.\n",
    "\n",
    "**¿Por que tomo tanta fuerza hasta hace tan poco?**\n",
    "\n",
    "Las redes neuronales artificiales necesitan conjuntos de datos muy grandes para ser entrenadas, pero a medida que se han creado tecnicas de machine learning y datos como lo permitio la creciente evolucion de internet, evolucionando la extraccion de datos y por tanto mejora el entrenamiento de esos algoritmos al igual que una mejora en el hardware osea recursos computacionales mas potentes para tratar grandes volumenes de informacion al igual de tratar algoritmos. Estos tipos de algoritmos hay que probarse de demasiadas maneras para verificar su funcionalidad y acierto.\n",
    "\n",
    "El deep learning se dice que se crearon a semejanza a las neuronas biologicas, pero tristemente no conocemos como funcionan nuestras neuronas ademas de que se conectan e intercambian informacion y se dice que son semejantes porque se conectan diferentes neuronas artificiales entre si que tienen diferentes pesos activando diferentes conexiones y respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ac1a5",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "- ¿Qué es?\n",
    "    - Es un algoritmo para encontrar el mínimo de una función (por ejemplo, la función de pérdida de un modelo). Imagina que estás en la cima de una colina y quieres bajar hasta el valle: gradient descent te indica en qué dirección y cuánto moverte en cada paso.\n",
    "\n",
    "- Intuición simple\n",
    "    - Calculas la pendiente (derivada) en el punto actual; esa pendiente te dice hacia dónde disminuye la función. Das un paso en esa dirección y repites hasta llegar al mínimo.\n",
    "\n",
    "- Pasos básicos\n",
    "    1. Inicializar los parámetros (por ejemplo θ).\n",
    "    2. Calcular el gradiente ∇J(θ) (la dirección de mayor aumento).\n",
    "    3. Actualizar: θ ← θ - α ∇J(θ), donde α es la tasa de aprendizaje (learning rate).\n",
    "    4. Repetir hasta convergencia o hasta un número fijo de iteraciones.\n",
    "\n",
    "- Fórmula clave\n",
    "    - θ ← θ - α ∇J(θ)\n",
    "\n",
    "- Puntos importantes\n",
    "    - α (learning rate): si es muy grande puedes saltarte el mínimo; si es muy pequeño, la convergencia será muy lenta.\n",
    "    - Puede converger a mínimos locales en funciones no convexas (como redes neuronales).\n",
    "    - Es útil normalizar las características para que el algoritmo converja más rápido.\n",
    "    - Variantes: batch (usando todo el conjunto), stochastic (un ejemplo a la vez), mini-batch (pequeños lotes) — mini-batch es la opción más común en deep learning.\n",
    "    - Mejoras comunes: momentum, RMSprop, Adam (más robustas y rápidas).\n",
    "\n",
    "- Ejemplo rápido (intuición matemática)\n",
    "    - Para f(x) = x^2, ∇f = 2x. La regla de actualización es x ← x - α·2x; iterando esto, x tiende a 0 (el mínimo).\n",
    "    \n",
    "- ¿Para qué se usa?\n",
    "    - Ajustar los parámetros de modelos de regresión, redes neuronales y, en general, cualquier problema donde necesitemos minimizar una función de pérdida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dc94b",
   "metadata": {},
   "source": [
    "# Redes neuronales artificiales y el PERCERTRON\n",
    "\n",
    "El perceptrón fue el primer modelo de neurona artificial funcional, propuesto por Frank Rosenblatt en 1957. Es un clasificador lineal sencillo que establece una frontera de decisión entre dos clases mediante una combinación lineal de entradas y una función de activación escalón.\n",
    "\n",
    "¿Qué hace y cómo funciona?\n",
    "- Representación: entradas x (vector), pesos w y sesgo b.\n",
    "- Salida: ŷ = 1 si w·x + b > 0, en caso contrario ŷ = 0 (o usando ±1 según la convención).\n",
    "- Regla de aprendizaje (perceptron learning rule): para cada ejemplo (x, y)\n",
    "    - predecir ŷ\n",
    "    - si hay error, actualizar: w ← w + η (y − ŷ) x, b ← b + η (y − ŷ), donde η es la tasa de aprendizaje.\n",
    "\n",
    "Propiedades clave\n",
    "- Convergencia: si los datos son linealmente separables, el algoritmo del perceptrón converge en un número finito de pasos (teorema de convergencia del perceptrón).\n",
    "- Limitaciones: no puede resolver problemas no linealmente separables (ej. la función XOR). Esa limitación fue señalada en el libro de Minsky y Papert (1969) y motivó críticas que ralentizaron la investigación durante una época.\n",
    "- Legado: aunque simple, el perceptrón sentó las bases conceptuales para redes neuronales más complejas (perceptrón multicapa) y estimuló el desarrollo de algoritmos como backpropagation y modelos de deep learning.\n",
    "\n",
    "Usos prácticos\n",
    "- Buen punto de partida pedagógico para entender clasificación lineal y actualización de pesos.\n",
    "- En la práctica se usa cuando la frontera entre clases es aproximadamente lineal; para problemas más complejos se requieren capas ocultas o modelos no lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4319f",
   "metadata": {},
   "source": [
    "**TLU $\\rightarrow$ Threshol logic unit**\n",
    "\n",
    "![tlu](Images/tlu.png)\n",
    "\n",
    "![funcion activacion](Images/acti.png)\n",
    "\n",
    "![percertron](Images/percertron.png)\n",
    "\n",
    "![train](Images/train.png)\n",
    "\n",
    "Limitaciones del Perceptrón\n",
    "* EI Perceptrón no proporciona como resultado una probabilidad, sino que realiza las predicciones basándose en un threshold estático\n",
    "* Construye límites de decisión lineales\n",
    "* EI uso de Perceptrones tiene grandes limitaciones, no permite resolver problemas sencillos como el problema de clasificación XOR\n",
    "* Más adelante, se descubre que muchas de las limitaciones del Perceptrón se solucionan añadiendo más capas de TLUs, apareciendo el Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d0577",
   "metadata": {},
   "source": [
    "# Perceptron Multicapa\n",
    "Se compone de un input layer y ademas de una o mas capas de TLUs, cada capa de TLU intermedia se denomina hidden layer (input y output layer). Ahora todas las capas estan conectadas unas entre otras entre capas y entre mas de 2 **hidden layers** se denomina __deep network neural__ (DNN).\n",
    "\n",
    "![multicapa](Images/multi.png)\n",
    "\n",
    "\n",
    "* Durante mucho tiempo una de las mayores limitación del Perceptrón Multicapa era que no existía una forma adecuada de entrenarlo\n",
    "* En 1986 D. E. Rumelhart presenta un algoritmo que revoluciona la manera de entrenar el Perceptrón Multicapa, el algoritmo backpropagation \n",
    "* EI cambio clave del algoritmo backpropagation respecto a los utilizados anteriormente fue remplazar la función de activación Heaviside Step function por la *sigmoide*\n",
    "* En la actualidad existen otras funciones de activación populares, como la *tanh(z)* o la *ReLU(z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358e8d3",
   "metadata": {},
   "source": [
    "# El gradient descent y la regresión logística\n",
    "\n",
    "## Resumen rápido\n",
    "- Gradient descent (GD) es una familia de algoritmos para minimizar una función de pérdida ajustando parámetros iterativamente en la dirección del gradiente negativo.\n",
    "- La regresión logística es un modelo lineal para clasificación binaria que estima la probabilidad de clase usando la función sigmoide y se entrena minimizando la entropía cruzada (log-loss) mediante optimizadores como GD.\n",
    "\n",
    "## Regresión logística: modelo y probabilidad\n",
    "- Modelo lineal: z = Xθ (X incluye sesgo/1).\n",
    "- Función sigmoide: σ(z) = 1 / (1 + e^{-z}).\n",
    "- Predicción de probabilidad: p(y=1|x) = σ(x^T θ).\n",
    "- Decisión: ŷ = 1 si p ≥ 0.5 (límite), o usar umbrales distintos según coste de errores.\n",
    "\n",
    "## Función de pérdida (binary cross-entropy / log-loss)\n",
    "- Para m ejemplos:\n",
    "    J(θ) = −(1/m) Σ [ y^{(i)} log p^{(i)} + (1−y^{(i)}) log (1−p^{(i)}) ].\n",
    "- Interpretación: máxima verosimilitud (MLE) bajo Bernoulli.\n",
    "\n",
    "## Gradiente (derivada) y regla de actualización\n",
    "- Vector de probabilidades p = σ(Xθ).\n",
    "- Gradiente: ∇J(θ) = (1/m) X^T (p − y).\n",
    "- Gradient descent (batch):\n",
    "    θ ← θ − α ∇J(θ),\n",
    "    donde α es la tasa de aprendizaje.\n",
    "- Para regularización L2: J_reg = J + (λ/2m) ||θ||^2, y el gradiente añade (λ/m) θ (no sobre el término de sesgo).\n",
    "\n",
    "## Variantes de optimización\n",
    "- Batch GD: usa todo el conjunto → estable pero costoso.\n",
    "- Stochastic GD (SGD): actualiza por ejemplo → ruido, converge rápido en grandes datos.\n",
    "- Mini-batch GD: compromete: eficiencia y estabilidad (batch típicos: 32–512).\n",
    "- Optimizadores adaptativos: Momentum, RMSprop, Adam (usualmente mejores para deep learning, Adam es frecuente en práctica).\n",
    "\n",
    "## Consideraciones prácticas y estabilidad numérica\n",
    "- Escalar/normalizar características (standardización o min-max) para mejor convergencia.\n",
    "- Inicialización de θ cerca de 0 (por ejemplo, pequeños aleatorios).\n",
    "- Elegir α adecuado: demasiado grande diverge, demasiado pequeño lento. Usar decaimiento del learning rate o validación.\n",
    "- Evitar overflow/underflow en σ: usar implementaciones numéricamente estables (p.ej. log-sum-exp, evitar calcular log(σ) directamente).\n",
    "- Regularización para evitar sobreajuste y para problemas con muchas características.\n",
    "- Balance de clases: ponderar la pérdida, sobremuestreo, umbral distinto o métricas apropiadas.\n",
    "\n",
    "## Evaluación\n",
    "- Métricas: accuracy, precision, recall, F1, AUC-ROC (importante cuando clases desbalanceadas).\n",
    "- Matriz de confusión y curvas ROC/PR para entender comportamiento según umbral.\n",
    "\n",
    "## Extensiones\n",
    "- Multiclase: softmax + cross-entropy (generaliza la sigmoid).\n",
    "    softmax(z)_k = exp(z_k) / Σ_j exp(z_j).\n",
    "- Features polinómicas o interacciones para fronteras de decisión no lineales.\n",
    "- Modelos lineales con núcleos o usar redes neuronales para relaciones complejas.\n",
    "\n",
    "## Intuición geométrica\n",
    "- Regresión logística aprende un hiperplano en el espacio de características que separa clases en términos de log-odds.\n",
    "- La frontera de decisión para p=0.5 es {x | θ^T x = 0}.\n",
    "\n",
    "## Consejos de implementación rápidos\n",
    "- Empieza con mini-batch + Adam; revisa over/underfitting con curvas de pérdida entrenamiento/validación.\n",
    "- Monitoriza gradientes (exploding/vanishing) y pérdidas; usa early stopping.\n",
    "- Regularización λ: buscar por validación (p. ej. grid search o búsqueda bayesiana).\n",
    "- Para producción, calibrar probabilidades si se requiere (p. ej. Platt scaling o isotonic).\n",
    "\n",
    "Resumen final: entender la relación entre la función de pérdida (entropía cruzada), la función sigmoide/softmax y el gradiente es clave; aplicar buenas prácticas (normalización, regularización, elección de optimizador y evaluación con métricas adecuadas) permite entrenar modelos de regresión logística robustos y bien calibrados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f3baf",
   "metadata": {},
   "source": [
    "![gradient y logistica](Images/rna_gradient_logistica.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553ba19",
   "metadata": {},
   "source": [
    "**Que es gradiente**\n",
    "\n",
    "El gradiente de una función es un vector que contiene sus derivadas parciales; indica la dirección de mayor aumento y su magnitud cuánto cambia la función en esa dirección. En optimización, el negativo del gradiente se usa para bajar la función (gradient descent), es decir, moverse en la dirección de mayor disminución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b55714",
   "metadata": {},
   "source": [
    "![gradiente](Images/gradiente.png)\n",
    "\n",
    "![error](Images/errorGra.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3729f0c",
   "metadata": {},
   "source": [
    "# Backpropagation — explicación muy fácil\n",
    "\n",
    "- Idea central: calcular cuánto contribuye cada peso al error final y ajustar los pesos para reducir ese error. Es \"echar la culpa\" hacia atrás desde la salida hasta las entradas usando la regla de la cadena.\n",
    "\n",
    "Pasos simples:\n",
    "1. Forward pass  \n",
    "    - Calculas salidas de la red: z = W·x + b, a = f(z) para cada capa, ŷ al final.\n",
    "2. Computar la pérdida L(y, ŷ) (p. ej. entropía cruzada).\n",
    "3. Backward pass (propagar el error hacia atrás)  \n",
    "    - Para la capa de salida: δ = ∂L/∂z = (∂L/∂ŷ) * f'(z).  \n",
    "    - Para una capa anterior: δ_l = (W_{l+1}^T · δ_{l+1}) * f'_l(z_l).  \n",
    "    - Gradientes: ∂L/∂W_l = δ_l · a_{l-1}^T, ∂L/∂b_l = δ_l.\n",
    "4. Actualizar pesos (gradiente descendente):  \n",
    "    - W_l ← W_l − α · ∂L/∂W_l,  b_l ← b_l − α · ∂L/∂b_l.\n",
    "\n",
    "Intuición breve:\n",
    "- La derivada f'(z) indica cuánto cambia la salida de una neurona si cambias su entrada.  \n",
    "- Multiplicando por W^T distribuyes el \"error\" hacia las neuronas anteriores (regla de la cadena).  \n",
    "- Repetir esto capa por capa te da exactamente cuánto debe cambiar cada peso para reducir la pérdida.\n",
    "\n",
    "Analogía:\n",
    "- Imagina varios controles (pesos) que afectan un resultado final malo. Backpropagation dice cuánto mover cada control para mejorar el resultado, empezando por el efecto visible (salida) y repartiendo responsabilidad hacia los controles anteriores.\n",
    "\n",
    "Consejos prácticos:\n",
    "- Usar activaciones con derivadas estables (ReLU, para evitar vanishing en algunas capas).  \n",
    "- Mini-batches y optimizadores (Adam) ayudan a converger más rápido.  \n",
    "- Frameworks (TensorFlow, PyTorch) hacen esto automáticamente con autograd.\n",
    "\n",
    "Resumen: forward para medir el error, backward para calcular gradientes con la regla de la cadena, actualizar pesos para mejorar la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a747d2",
   "metadata": {},
   "source": [
    "![backpropagation](Images/backpropagation.png)\n",
    "\n",
    "![a](Images/a.png)\n",
    "\n",
    "![b](Images/b.png)\n",
    "\n",
    "![c](Images/c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca8be5",
   "metadata": {},
   "source": [
    "# Tipos de Redes Neuronales Profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd404b",
   "metadata": {},
   "source": [
    "## Redes Neuronales Fully Connected (Totalmente Conectadas / Dense)\n",
    "\n",
    "Las redes fully connected son arquitecturas en las que cada neurona de una capa está conectada a todas las neuronas de la capa siguiente. Suelen componerse de una capa de entrada, una o varias capas ocultas y una capa de salida.\n",
    "\n",
    "Concepto básico\n",
    "- Forward pass: para cada capa l: z_l = W_l · a_{l-1} + b_l, a_l = f(z_l) donde f es la función de activación (ReLU, sigmoid, tanh, etc.).\n",
    "- Entrenamiento: se minimiza una función de pérdida mediante backpropagation y un optimizador (SGD, Adam, ...).\n",
    "\n",
    "Ventajas\n",
    "- Simplicidad y expresividad: pueden aproximar funciones arbitrarias con suficientes neuronas/capas.\n",
    "- Buen punto de partida para problemas tabulares y como bloque en arquitecturas híbridas.\n",
    "\n",
    "Limitaciones\n",
    "- Gran número de parámetros → riesgo de sobreajuste y coste computacional.\n",
    "- No explotan estructuras espaciales o secuenciales (para imágenes o texto conviene CNNs o RNN/Transformers).\n",
    "- Pueden sufrir problemas de vanishing/exploding gradients en redes muy profundas.\n",
    "\n",
    "Buenas prácticas\n",
    "- Normalizar/estandarizar características de entrada.\n",
    "- Inicialización adecuada de pesos (He para ReLU, Xavier para sigmoid/tanh).\n",
    "- Usar activaciones modernas (ReLU/LeakyReLU) para capas ocultas.\n",
    "- Regularización: L2, dropout y/o early stopping para evitar overfitting.\n",
    "- Batch normalization para estabilizar y acelerar el entrenamiento.\n",
    "- Elegir tamaño y número de capas por validación (usar validación cruzada o set de validación).\n",
    "\n",
    "Casos de uso típicos\n",
    "- Modelado en datos tabulares, regresión y clasificación sencillas, y como capas finales en modelos más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5612e4",
   "metadata": {},
   "source": [
    "## Redes Neuronales Convolucionales (CNN)\n",
    "\n",
    "- ¿Qué son?  \n",
    "    - Arquitecturas diseñadas para procesar datos con estructura de grilla (p. ej. imágenes). Extraen características locales mediante filtros (kernels) compartidos y construyen representaciones jerárquicas.\n",
    "- Operación clave: convolución  \n",
    "    - Un kernel desliza sobre la entrada y calcula productos punto → mapas de características (feature maps). Parámetros: tamaño del kernel, stride (paso) y padding (relleno).\n",
    "- Intuición  \n",
    "    - Las primeras capas capturan bordes y texturas; capas intermedias combinan patrones simples en formas más complejas; las capas profundas detectan objetos/rasgos semánticos.\n",
    "- Forward y entrenamiento  \n",
    "    - Forward: conv → activación (ReLU) → pooling (opcional) → batch-norm → repetición → fully connected → softmax/log-loss.  \n",
    "    - Entrenamiento: backprop + optimizadores (Adam, SGD con momentum), mini-batches y data augmentation.\n",
    "- Ventajas y limitaciones  \n",
    "    - Ventajas: parámetros compartidos (menos parámetros), invarianza local, excelente para visión.  \n",
    "    - Limitaciones: requieren muchos datos, sensibles a transformaciones no vistas (aunque se mitiga con augmentación), costo computacional en modelos grandes.\n",
    "\n",
    "### Componentes, arquitecturas y buenas prácticas\n",
    "\n",
    "- Componentes comunes  \n",
    "    - Convolutional layers (kernels 3×3 o 5×5), Pooling (max/avg), Batch Normalization, Activaciones (ReLU/LeakyReLU), Dropout, Fully Connected finale, Skip connections (ResNet).\n",
    "- Arquitecturas clásicas  \n",
    "    - LeNet → AlexNet → VGG → Inception → ResNet. Cada una introduce mejoras: mayor profundidad, módulos eficientes o conexiones residuales.\n",
    "- Buenas prácticas  \n",
    "    - Normalizar entradas, usar inicializaciones apropiadas (He para ReLU), emplear augmentación (rotación, recorte, flip, color jitter), usar transfer learning en datasets pequeños, monitorizar over/underfitting con curvas de pérdida, ajustar learning rate (schedulers), usar batch-norm y regularización (weight decay, dropout).\n",
    "- Consideraciones prácticas  \n",
    "    - Tamaño del batch y memoria GPU afectan el entrenamiento. Usar mixed precision para acelerar. Evaluar con métricas de clasificación y visualizaciones (mapas de activación, Grad-CAM) para interpretabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b41ff",
   "metadata": {},
   "source": [
    "## Redes Neuronales Recurrentes (RNN)\n",
    "\n",
    "- ¿Qué son?  \n",
    "    - Arquitecturas diseñadas para procesar datos secuenciales (texto, series temporales, audio). Mantienen un estado oculto que acumula información de pasos anteriores y permite modelar dependencias temporales.\n",
    "\n",
    "- Operación clave  \n",
    "    - En cada paso temporal t: h_t = f(W_x x_t + W_h h_{t-1} + b), y opcionalmente y_t = g(V h_t + c). El estado oculto h actúa como memoria que se actualiza paso a paso.\n",
    "    - Tipos de retorno: unidireccional (hacia adelante), bidireccional (procesa la secuencia en ambas direcciones).\n",
    "\n",
    "- Intuición  \n",
    "    - Las RNN \"recuerdan\" información previa a través del estado oculto; útil cuando la predicción depende de contexto histórico (p. ej. palabras previas en una oración).\n",
    "\n",
    "- Forward y entrenamiento  \n",
    "    - Forward: se recorre la secuencia actualizando h_t y produciendo salidas intermedias o finales.  \n",
    "    - Backpropagation Through Time (BPTT): se desenvuelve la red en el tiempo y aplica backprop para acumular gradientes a lo largo de los pasos.  \n",
    "    - Variantes: entrenamiento por truncamiento de BPTT (truncated BPTT) para secuencias largas; teacher forcing en modelos seq2seq.\n",
    "\n",
    "- Ventajas y limitaciones  \n",
    "    - Ventajas: modelan información temporal, compacidad para secuencias cortas/medias, útiles en tareas de lenguaje, series temporales y audio.  \n",
    "    - Limitaciones: dificultades con dependencias a muy largo plazo por vanishing/exploding gradients en RNNs simples; cómputo secuencial que dificulta paralelización; pueden ser reemplazadas por arquitecturas basadas en atención (Transformers) en muchos casos.\n",
    "\n",
    "- Componentes, arquitecturas y buenas prácticas\n",
    "\n",
    "    - Arquitecturas comunes  \n",
    "        - Vanilla RNN (simple): útil pedagógicamente pero limitado por gradientes.  \n",
    "        - LSTM (Long Short-Term Memory): introduce puertas (input, forget, output) y celda de memoria para manejar dependencias largas.  \n",
    "        - GRU (Gated Recurrent Unit): variante más simple que LSTM con rendimiento comparable en muchas tareas.  \n",
    "        - Bidirectional RNNs: concatenan contexto pasado y futuro para tareas donde la secuencia completa está disponible.  \n",
    "        - Seq2Seq (encoder–decoder) y attention: para traducción, resumen y tareas de generación; la atención mejora la gestión de long-range dependencies.\n",
    "\n",
    "    - Buenas prácticas  \n",
    "        - Usar LSTM/GRU en lugar de RNNs básicas para dependencias largas.  \n",
    "        - Aplicar gradient clipping para evitar exploding gradients.  \n",
    "        - Normalización (layer norm) y dropout recurrente para regularizar.  \n",
    "        - Truncar BPTT para secuencias demasiado largas; usar batching con padding y máscaras.  \n",
    "        - Inicializar pesos adecuadamente y ajustar el learning rate (schedulers).  \n",
    "        - En tareas generativas, emplear teacher forcing durante el entrenamiento y técnicas de sampling controlado en inferencia.  \n",
    "        - Considerar Transformers/attention cuando se requiera paralelización y manejo eficiente de dependencias globales.\n",
    "\n",
    "    - Casos de uso típicos  \n",
    "        - Modelado de lenguaje, traducción automática, reconocimiento de voz, predicción de series temporales, etiquetado secuencial (NER, POS), y generación de secuencias.\n",
    "\n",
    "Resumen: las RNNs y sus variantes con puertas (LSTM/GRU) son la elección clásica para secuencias; sin embargo, en problemas con dependencias muy largas o necesidad de paralelismo, las arquitecturas basadas en atención suelen ofrecer mejores resultados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
